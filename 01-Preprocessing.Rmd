---
title: "Realized Higher Moment Measures of Equity Returns"
description: |
  Part 1: Data Preprocessing
author:
  - name: Alexis Solis Cancino
    url: alexis.solisc@gmail.com
    affiliation: ITAM
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    code_folding: true
    theme: "resources/theme.css"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

# --- set chunk options ---
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = FALSE
)


# --- Load libraries ---
library(tidyverse)   # core-data-science
library(janitor)     # quick data cleansing
library(arrow)       # for columnar super-fast manipulation
library(lubridate)   # working with dates
library(hms)         # working with times
library(here)        # path management
# library(readxl)


# --- Modeling Time Series ---
library(timetk)


# --- Source ggplot2 themes ---
source(here("resources/ggplot2_themes.R"))
```

# 1. Introduction & Importing Data

We'll work with intraday data for the *S&P/BMV IPC Equity Index*. The data consists of `n = 2,133,890` observations and `k = 23` variables. The time-series is composed of prices and trades per minute, spanning from the beginning of 1996 through the first half of 2018.

The first step is, of course, importing the data:

```{r, echo = T}
# Read the parquet file that contains raw data
ipc_intraday <- read_parquet(file = here("data-raw/raw_MEXICO_IPC.parquet"))
```

First thing we do is take a look at the columns and data types that we have:

```{r}
ipc_intraday %>% glimpse()
```

So we have `boolean`, `character`, `numeric` and `time` types of columns. We also note that the names are not very friendly to work with. We fix that by creating a _string_ vector and using that to replace the names in our data. The new names are:

```{r}
# Create vector with new column names
column_names <- c("ticker","raw_date","raw_time","type",
                  "open","high","low","last","volume",
                  "average_price","vwap","no_trades",
                  "correction_qualifiers","open_bid",
                  "high_bid","low_bid","close_bid",
                  "no_bids","open_ask","high_ask","low_ask",
                  "close_ask","no_ask")

# Rename the columns
ipc_intraday <- ipc_intraday %>% set_names(column_names)

# Print names
ipc_intraday %>% names()
```

## 1.1 Missing values

There seem to be many missing values in the data, so let's count them! We do this per column:

```{r}
map_df(ipc_intraday, ~ sum(is.na(.x))) %>% 
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "missing_count"
  ) %>% 
  arrange(-missing_count) %>% 
  print(n = 23L)
```

We see that there are 10 columns that have all values as `NA`, therefore we can remove all of these variables. The variables to remove are:

```{r}
# Get which columns have all values as NAs.
columns_to_remove <- map_df(ipc_intraday, ~ sum(is.na(.))) %>%
  pivot_longer(cols = everything(), 
               names_to = "variable", 
               values_to = "no_missing") %>% 
  filter(no_missing > 0) %>%
  pull(variable)

# Print the selected columns.
columns_to_remove
```

Thus, our data is now leaner, and it includes the following variables:

```{r}
# Get a new dataset without the selected columns
ipc_intraday <- ipc_intraday %>% select(-all_of(columns_to_remove))

# Print names
ipc_intraday %>% names()
```

# 2. Feature Engineering & Data Wrangling

We then carry on with the analysis by creating some new variables (a.k.a. *Feature Engineering*) and manipulating the data. The first manipulations we do are the following:

1.  First, a `tidy_date` variable is created, where the date is parsed according to the *ISO 8601* standard that states that dates should be expressed in the `YYYY-MM-DD` format. In consequence, the `raw_date` column is dropped and is replaced by the newly created `tidy_date` variable.

2.  The `raw_time` column is replaced for the `tidy_time` variable, which parses the time correctly.

3.  The `no_bids`, `no_ask`, `average_price`, `ticker`, `type`, `open`, `high`, and `low` columns are removed because (we think) they are of no use for the analysis.

4.  We rename the `last` variable as `last_price`.

```{r}
ipc_intraday <- ipc_intraday %>% 
  
  # Create time variables: tidy_date, tidy_time, tidy_dttm
  mutate(tidy_date = lubridate::ymd(raw_date),
         tidy_time = hms::as_hms(raw_time)
         ) %>%
  
  # Remove some columns
  select(-c(raw_date, raw_time, ticker, type, open, high, low, no_bids, no_ask, average_price)) %>% 
  
  # Get newly created variable to the beginning of tibble
  relocate(starts_with("tidy"), .before = 1) %>% 
  
  # Rename "last" variable
  rename(last_price = last)

# Print the new dataset
ipc_intraday
```


## 2.1 Exploring the time window for prices

Now, let's explore both the `tidy_date` and `tidy_time` variables. First, it's useful to see how many unique dates (i.e. the number of trading-days) are present in the data.

```{r}
n_days <- ipc_intraday %>% 
  distinct(tidy_date) %>% 
  nrow()

# Print the number of days
n_days %>% format(big.mark = ",")
```

So we have `r n_days %>% format(big.mark = ",")` different trading-days.

Now, regarding the `tidy_time` variable, the data shows that we have prices from **05:32 a.m.** all the way through **08:22 p.m.**

```{r}
earliest_times <- ipc_intraday %>% 
  select(tidy_time) %>% 
  unique() %>% 
  arrange(tidy_time) %>% 
  head() %>% 
  pull()

latest_times <- ipc_intraday %>% 
  select(tidy_time) %>% 
  unique() %>% 
  arrange(desc(tidy_time)) %>% 
  head() %>% 
  pull()

tibble(
  earliest = earliest_times,
  latest = latest_times
)
```

We can also visualize how many datapoints we have, per hour.

```{r, layout="l-body-outset", fig.width=8, fig.asp=0.618}
ipc_intraday %>% 
  mutate(tidy_hour = as.factor(hour(tidy_time))) %>% 
  count(tidy_hour, sort = T, name = "trades_per_hour") %>% 
  # mutate(tidy_hour = fct_reorder(tidy_hour, .x = trades_per_hour, .desc = T)) %>%
  ggplot(aes(tidy_hour, trades_per_hour)) +
  geom_col(aes(fill = between(x = as.numeric(tidy_hour), 
                              left = 5, 
                              right = 10)),
           show.legend = F) +
  scale_fill_manual(values = amazing_colors[c(2,8)]) +
  scale_y_continuous(labels = scales::number_format(big.mark = ",")) +
  labs(
    title = "No. Prices per Hour in the Sample",
    x = "Hour",
    y = NULL
  )
```

From the plot above, we see that most of the prices lie between 8:00AM - 3:00PM. It's interesting that the hours `8` and `15` have fewer datapoints. We can further inspect each one to see the hour-minute components of those trades.

```{r, layout="l-body-outset", fig.width=8, fig.asp=0.618}
ipc_intraday %>% 
  mutate(tidy_hour = as.factor(hour(tidy_time)),
         tidy_minute = minute(tidy_time)) %>%
  filter(tidy_hour == 8) %>% 
  count(tidy_minute, sort = T, name = "trades_per_minute") %>% 
  ggplot(aes(tidy_minute, trades_per_minute)) +
  geom_col(aes(fill = tidy_minute < 30),
           show.legend = F) +
  scale_fill_manual(values = amazing_colors[c(8,2)]) +
  scale_x_continuous(breaks = seq(0, 60, 5)) +
  scale_y_continuous(
    labels = scales::number_format(big.mark = ","),
    breaks = seq(0, 5000, length.out = 11)
    ) +
  labs(
    title = "Number of Trades per Minute from 8:00AM-8:59AM",
    x = "Minute",
    y = NULL
  )
```

As expected, the second half-hour is the most active (that is, the period from 8:30AM - 8:59AM).

Now, let's do the same for the `15` hour-mark:

```{r, layout="l-body-outset", fig.width=8, fig.asp=0.618}
ipc_intraday %>% 
  mutate(tidy_hour = as.factor(hour(tidy_time)),
         tidy_minute = minute(tidy_time)) %>%
  filter(tidy_hour == 15) %>% 
  count(tidy_minute, sort = T, name = "trades_per_minute") %>% 
  ggplot(aes(tidy_minute, trades_per_minute)) +
  geom_col(aes(fill = trades_per_minute > 2500),
           show.legend = F) +
  scale_fill_manual(values = amazing_colors[c(2,8)]) +
  scale_x_continuous(breaks = seq(0, 60, 5)) +
  scale_y_continuous(labels = scales::number_format(big.mark = ",")) +
    labs(
    title = "Number of Trades per Minute from 3:00PM-3:59PM",
    x = "Minute",
    y = NULL
  )
```

Here, the time with most trades is 3:00PM exactly. Following *Liu, Patton, Sheppard (2013)*, we'll discard any prices that were quoted outside normal business hours. Hence, we want prices that lie between `08:30` and `15:00`.

To achieve this, we'll introduce the concept of a *time series index*.

### 2.1.1 Time Series Index

Before we continue, we must create the so called **time series index**. To achieve this, a `dttm` (*datetime*) variable is created, which is the result of combining the `tidy_date` variable and the `tidy_time` variable. This combination gets the name of `tidy_dttm`. In this case, this is the variable by which the time series will be indexed. Below we print a small sample (first 6 rows) of this variable index:

```{r creating-tidy-dttm, cache=TRUE}
ipc_intraday <- ipc_intraday %>% 
  
  # Add time series index: tidy_dttm
  mutate(tidy_dttm = ymd_hms(str_c(tidy_date, tidy_time))) %>%
  
  relocate(tidy_dttm, .before = 1)

ipc_intraday %>% select(tidy_dttm) %>% head()
```

Next, in order to know the *edges* of the _datetime_ variable, we can get the first and last values in the time series. We name these values `left_edge` (first value) and `right_edge` (last value), respectively.

```{r}
left_edge <- ipc_intraday %>%
  
  # Arrange in descending tidy_dttm order
  arrange(tidy_dttm) %>% 
  
  # Get the vector
  pull(tidy_dttm) %>% 
  
  # Get the first element of the vector
  first()

right_edge <- ipc_intraday %>% 
  
  # Arrange in descending tidy_dttm order
  arrange(tidy_dttm) %>% 
  
  # Get the vector
  pull(tidy_dttm) %>% 
  
  # Get the last element of the vector
  last()

paste("The first date-time in our data is:", left_edge) 
paste("The last date-time in our data is:", right_edge) 
```

These values are incorrect; the first value in our time-series should be `1996-01-02 08:30:00` and the last one should be: `2018-06-05 15:00:00`. The Time Series Index will be defined based on these *correct* values. These will be created as the `first_dttm` and `last_dttm` variables.

```{r}
first_dttm <- left_edge %>% 
  as_date() %>% 
  paste("08:30:00") %>% 
  as_datetime()

last_dttm <- right_edge %>% 
  as_date() %>% 
  paste("15:00:00") %>% 
  as_datetime()
```

### 2.1.2 Adjustments to the Time Series Index

Below, we print the first and last 10 values of the `ts_index` object (the *time series index*).

```{r}
# Make index by using vectorized function
ts_index <- tibble(
  
  index = timetk::tk_make_timeseries(start_date = first_dttm,
                                     end_date = last_dttm,
                                     by = "60 sec")
) %>% 
  
  # Create date and time columns
  mutate(index_date = as_date(index),
         
         index_time = hms(seconds = second(index),
                          minutes = minute(index),
                          hours = hour(index)
                          )
         ) %>% 
  
  # Filter for times between 08:30 and 15:00
  filter(index_time >= as_hms("08:30:00"),
         index_time <= as_hms("15:00:00")) %>% 
  
  # Get rid of absent dates  
  filter(index_date %in% ipc_intraday$tidy_date)

# Print first 10 values
ts_index

# Print last 10 values
ts_index %>% 
  arrange(desc(index))
```

Note that we've removed the dates that don't match those from the original data. This gets rid of weekends, too.

### 2.1.3 Joining the Data

We will make some checks further down the line, but for now, the data is ready to be **joined** into a new object, so that we have **no gaps** in between the 1-minute prices.

```{r}
ipc_intraday <- ts_index %>% 
  left_join(
    ipc_intraday,
    by = c("index" = "tidy_dttm")) %>% 
  
  # Remove useless columns
  select(-c(tidy_date, tidy_time))
```

Below, we print the first 10 rows of this joined data. It's evident that many prices have an `NA` value, because they're not available. We'll *impute* these next.

```{r}
ipc_intraday
```


## 2.2 Price Imputation

We can check how many missing prices we have in the data:

```{r}
ipc_intraday %>% 
  filter(is.na(last_price)) %>% 
  count() %>% 
  pull(n) %>% 
  format(big.mark = ",")
```

So we have almost 92K missing prices, which represent a little over 4% of the total data. Therefore, it is acceptable if we impute the prices. We also have missing data for `volume` and number of trades(`no_trades`). These can be imputed easily: substituting a zero everytime there's no price data (this is a reasonable imputation). First, let's check how many missing values we have per column:

```{r}
ipc_intraday %>% 
  map_df(.f = ~ sum(is.na(.))) %>% 
  pivot_longer(
    cols = everything(), 
    names_to = "variable", 
    values_to = "missing_count"
    )
```

We now impute the volume and number of trades and check that indeed there are no missing values:

```{r}
# Impute volume and no_trades
ipc_intraday <- ipc_intraday %>% 
  mutate(
    volume = if_else(is.na(last_price), 0, volume),
    no_trades = if_else(is.na(last_price), 0, no_trades)
  ) 

ipc_intraday %>% 
  map_df(.f = ~ sum(is.na(.))) %>% 
  pivot_longer(
    cols = everything(), 
    names_to = "variable", 
    values_to = "missing_count"
    )
```


Except for the first 6 data points, we will impute the prices by looking at the  last available price. For the first 6 data points, we take a look at the first non-missing price, and use that one as a replacement value.

```{r}
# Impute first 6 prices
ipc_intraday$last_price[1:6] <- ipc_intraday$last_price[7]

# Impute the rest of the prices using fill()
ipc_intraday <- ipc_intraday %>% 
  fill(last_price)
  
ipc_intraday %>% 
  map_df(.f = ~ sum(is.na(.))) %>% 
  pivot_longer(
    cols = everything(), 
    names_to = "variable", 
    values_to = "missing_count"
    )
```

Another check we can do is to count the number of prices per unique date. We can do this by just counting the frequency of each date. It must have a frequency of 391, since we have:

\begin{equation} 
\text{prices/day} = \text{hours} \times \text{minutes} + 1 = (6.5) \times 60 + 1 = 391 
\end{equation}

```{r}
ipc_intraday %>% 
  count(index_date, name = "date_count")
```

Printing the first 10 counts for each date... this looks correct. But now, let's get the unique values from that `date_count` column just to be sure:

```{r}
ipc_intraday %>% 
  count(index_date, name = "date_count") %>% 
  distinct(date_count)
```

The time series has been successfully padded.

## 2.3 Time Series Signature

We can now create several time-related variables from the time series index. In this case, we'll get *20 different time-related variables*. We'll call this the **Time Series Signature**, which is a collection of time-related variables that will help for feature engineering and modeling. The variables computed are the following:

-   `index`: The time-index variable that is being decomposed.
-   `index_date`: The date component of the `index` variable.
-   `index_time`: The time component of the `index` variable.
-   `index_num`: The numeric value of the time series index (in seconds). The base is `1970-01-01 00:00:00` which has the value of 0.
-   `diff`: The difference (in seconds) from the previous numeric `index` value.
-   `year`: The year of the *time series* `index`.
-   `half`: The *half component* of the index (i.e. to which semester does the date belong to).
-   `quarter`: The *quarter component* of the index (i.e. to which quarter does the date belong to).
-   `month`: The *month component* of the index (with base 1 - that is, January = 1 and so on).
-   `month_label`: The three-letter month label as an ordered categorical variable. It begins with *Jan* and ends with *Dec*.
-   `day`: The *day* component of the `index`.
-   `hour`: The *hour* component of the `index` (24-hour scale).
-   `minute`: The *minute* component of the `index` (from 0 - 59).
-   `wday`: The day of the week with base 1. Monday = 1 and Sunday = 7.
-   `wday_label`: The three-letter label for day of the week as an ordered categorical variable. It begins with `Mon` and ends with `Sun`.
-   `qday`: The day of the quarter.
-   `yday`: The day of the year.
-   `mweek`: The week of the month.
-   `week`: The week number of the year.
-   `mday7`: The integer division of the day of the month by seven, which returns the *nth* instance the day has appeared in that month.
-   `date_change`: A *boolean* variable. `TRUE` indicates that the date has changed against the previous index value. `FALSE` indicates no change.

```{r}
ipc_intraday <- ipc_intraday %>% 
  
  # Create time series signature
  mutate(
    index_num   = as.numeric(index),
    diff        = index_num - lag(index_num),
    year        = year(index),
    half        = semester(index, with_year = FALSE),
    quarter     = quarter(index),
    month       = month(index),
    month_label = month(index, label = TRUE),
    day         = day(index),
    hour        = hour(index),
    minute      = minute(index),
    wday        = wday(index, week_start = 1),
    wday_label  = wday(index, label = TRUE),
    qday        = qday(index),
    yday        = yday(index),
    # mweek       =
    # week        = lubridate::week(),
    # mday7       = day %% 7,
    date_change = if_else(index_date == lag(index_date), FALSE, TRUE)
  )
```

Lastly, we do a quick check for:

1.  The time series signature doesn't contain weekend days. We check this by printing the unique values for the weekday label stored in the `wday_label` variable.

```{r}
ipc_intraday %>% 
  distinct(wday_label)
```

2.  The time signatures only contains hours from `08:00` through `15:00`. To be sure, we print the first and last 6 unique values of the `index_time` variable.

```{r}
# First 10 unique values
earliest_index <- ipc_intraday %>% 
  distinct(index_time) %>% 
  head() %>% 
  pull(index_time)

# Last 10 unique values
latest_index <- ipc_intraday %>% 
  arrange(-index_time) %>% 
  distinct(index_time) %>% 
  head() %>% 
  pull(index_time)

tibble(
  earliest = earliest_index,
  latest = latest_index
)
```

## 2.4 Computing Intraday Log-Returns

We are finally ready to compute the intraday returns. We name the column `log_ret`.

```{r}
ipc_intraday <- ipc_intraday %>%
  
  # Compute log-returns
  mutate(log_ret = log(last_price) - lag(log(last_price))) %>% 
  
  # Relocate the columns
  relocate(index_date, index_time, log_ret, everything())

ipc_intraday
```

## 2.5 Setting Overnight Returns to NA

For modeling purposes, we will assume that there is no overnight return. Therefore, we set the first log-return of each day to `NA`. The value `NA` is chosen because it will be useful for data-wrangling purposes.

```{r}
ipc_intraday <- ipc_intraday %>% 
   
  mutate(log_ret = ifelse(test = date_change == FALSE,
                          yes = log_ret, 
                          no = NA))
```

We should only have one `NA` value per day. Let's check that it is the case. We do that by checking that both numbers are equal, if that's the case, we'll get a `TRUE` value as output.

```{r}
total_na <- ipc_intraday %>% 
  filter(is.na(log_ret)) %>% 
  nrow()

total_dates <- ipc_intraday %>% 
  distinct(index_date) %>% 
  nrow()

# Check for equality
all.equal(total_na, total_dates)
```

We can check that all overnight returns are `NA`s. The variable `date_change` from the *time series index* is useful here. We extract the distinct values of the `log_ret` variable along with the `date_change` variable. We should get that all values for `date_change` are `TRUE`, and all values for `log_ret` are `NA`.

```{r}
ipc_intraday %>% 
  filter(date_change == 1) %>% 
  distinct(log_ret, date_change) 
```

Moreover, the number of overnight returns that have been set to `NA` should be one less than the number of different dates we have for the `tidy_date` variable. Let's check if this holds true:

```{r}
ipc_intraday %>% 
  filter(date_change == TRUE) %>% 
  select(index_date, log_ret, date_change) %>% 
  nrow() %>% 
  format(big.mark = ",")
```

We have *5,612* datapoints where `date_change = TRUE`. This should be one less than the amount of different dates (one less because the first date doesn't have `date_change` set to one).

```{r}
ipc_intraday %>% 
  distinct(index_date) %>% 
  nrow() %>% 
  format(big.mark = ",")
```

We see that this holds true. We have correctly set the overnight returns to `NA`.


## 2.6 Removing Outliers

Removing outliers in the log-return data is important. Therefore, we filter out log-returns whose absolute value is greater than some **predefined threshold**. We'll do this again later for 5-minute returns and 30-minute returns. We define the threshold such that we don't have anomalous 1-minute log-returns and at the same time, we are keeping \~ 99% of the original data. Log-returns that are outside of the defined threshold are immediately set to zero.

```{r}
# Predefined threshold
threshold <- .10

ipc_intraday <- ipc_intraday %>% 
  
  # we keep values below the threshold
  mutate(log_ret = ifelse(test = abs(log_ret) < threshold, 
                          yes = log_ret, 
                          no = 0)
         )
```

In this case we've set the variable `threshold` to the value `.10` as having a 10% 1-minute return would be extremely rare (most probably a mistake in the data). Fortunately, in this case, we have no anomalous returns so no log-return data had to be removed.

## 2.7 Final Data

After all this preprocessing steps, we are ready to write to data to disk. We will use this preprocessed data when working on Realized Variance Analysis and Volume Analysis.

```{r}
# Write data to parquet
ipc_intraday %>% 
  write_parquet(sink = here("data-processed/intraday_ipc.parquet"))
```